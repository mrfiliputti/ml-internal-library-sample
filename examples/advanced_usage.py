"""
Exemplo Avan√ßado - Time de Data Science

Este exemplo demonstra recursos avan√ßados da biblioteca:
- Valida√ß√£o de dados
- An√°lise de import√¢ncia de features
- Salvamento/carregamento de modelos
- Intervalos de confian√ßa

Uso:
    python examples/advanced_usage.py
"""

import sys
from pathlib import Path
import pandas as pd

from src import (
    DataIngestion,
    DataValidator,
    ModelTrainer,
    ModelEvaluator,
    save_pickle,
    load_pickle
)


def validar_qualidade_dados(data: pd.DataFrame) -> dict:
    """Valida qualidade dos dados antes do treinamento."""
    print("\nüîç Validando qualidade dos dados...")
    
    validator = DataValidator(data)
    
    # Define tipos esperados
    expected_types = {
        'year': 'int',
        'mileage': 'int',
        'engine_size': 'float',
        'horsepower': 'int',
        'num_doors': 'int',
        'price': 'float'
    }
    
    # Executa valida√ß√µes
    results = validator.validate_all(expected_types=expected_types)
    
    # Exibe resumo
    print(validator.get_summary())
    
    return results


def analisar_importancia_features(trainer: ModelTrainer, feature_names: list) -> None:
    """Analisa e exibe import√¢ncia das features."""
    print("\nüìä An√°lise de Import√¢ncia das Features:")
    print("-" * 70)
    
    importance = trainer.get_feature_importance()
    
    if importance is not None:
        # Ordena por import√¢ncia absoluta
        feature_importance = pd.DataFrame({
            'Feature': feature_names,
            'Coeficiente': importance,
            'Import√¢ncia_Abs': abs(importance)
        }).sort_values('Import√¢ncia_Abs', ascending=False)
        
        print(feature_importance.to_string(index=False))
        
        # Identifica features mais importantes
        top_feature = feature_importance.iloc[0]
        print(f"\nüèÜ Feature mais importante: {top_feature['Feature']}")
        print(f"   Coeficiente: {top_feature['Coeficiente']:.2f}")


def gerar_relatorio_completo(evaluator: ModelEvaluator) -> None:
    """Gera relat√≥rio completo de avalia√ß√£o."""
    print("\nüìà Relat√≥rio Completo de Avalia√ß√£o:")
    print(evaluator.get_report())
    
    # Intervalos de confian√ßa
    intervals = evaluator.calculate_prediction_intervals(confidence=0.95)
    print("\nüéØ Intervalos de Confian√ßa (95%):")
    print(f"   ‚Ä¢ Calculados para {len(intervals['lower_bound'])} predi√ß√µes")
    print(f"   ‚Ä¢ Amplitude m√©dia: ${(intervals['upper_bound'] - intervals['lower_bound']).mean():,.2f}")


def salvar_modelo_producao(trainer: ModelTrainer, output_dir: str = "models") -> None:
    """Salva modelo para uso em produ√ß√£o."""
    print(f"\nüíæ Salvando modelo em produ√ß√£o...")
    
    Path(output_dir).mkdir(exist_ok=True)
    
    model_path = f"{output_dir}/production_model.pkl"
    scaler_path = f"{output_dir}/production_scaler.pkl"
    
    trainer.save(model_path, scaler_path)
    
    print(f"   ‚úì Modelo salvo: {model_path}")
    print(f"   ‚úì Scaler salvo: {scaler_path}")


def demonstrar_carregamento_modelo(data_teste: pd.DataFrame) -> None:
    """Demonstra como carregar e usar modelo salvo."""
    print("\nüìÇ Demonstrando carregamento de modelo salvo...")
    
    try:
        # Carrega modelo e scaler
        model = load_pickle("models/production_model.pkl")
        scaler = load_pickle("models/production_scaler.pkl")
        
        print("   ‚úì Modelo carregado com sucesso!")
        
        # Faz predi√ß√£o
        X_scaled = scaler.transform(data_teste)
        prediction = model.predict(X_scaled)
        
        print(f"   ‚úì Predi√ß√£o realizada: ${prediction[0]:,.2f}")
        
    except FileNotFoundError:
        print("   ‚ö†Ô∏è Modelo n√£o encontrado. Execute o salvamento primeiro.")


def main():
    """Exemplo avan√ßado com todos os recursos."""
    
    print("=" * 70)
    print("EXEMPLO AVAN√áADO - TIME DE DATA SCIENCE")
    print("=" * 70)
    
    # ========================================
    # 1. INGEST√ÉO E VALIDA√á√ÉO
    # ========================================
    print("\n[ETAPA 1] INGEST√ÉO E VALIDA√á√ÉO DE DADOS")
    print("-" * 70)
    
    ingestion = DataIngestion("data/cars.csv")
    data = ingestion.generate_synthetic_data(n_samples=1000, random_state=42)
    
    # Valida qualidade
    validation_results = validar_qualidade_dados(data)
    
    # ========================================
    # 2. PREPARA√á√ÉO DOS DADOS
    # ========================================
    print("\n[ETAPA 2] PREPARA√á√ÉO DOS DADOS")
    print("-" * 70)
    
    X_train, X_test, y_train, y_test = ingestion.split_data(
        test_size=0.2,
        random_state=42
    )
    
    print(f"‚úì Dados divididos: {len(X_train)} treino, {len(X_test)} teste")
    
    # ========================================
    # 3. TREINAMENTO COM AN√ÅLISE
    # ========================================
    print("\n[ETAPA 3] TREINAMENTO E AN√ÅLISE")
    print("-" * 70)
    
    trainer = ModelTrainer(use_scaling=True)
    trainer.fit(X_train, y_train)
    
    print("‚úì Modelo treinado")
    
    # Analisa import√¢ncia das features
    analisar_importancia_features(trainer, X_train.columns.tolist())
    
    # ========================================
    # 4. AVALIA√á√ÉO DETALHADA
    # ========================================
    print("\n[ETAPA 4] AVALIA√á√ÉO DETALHADA")
    print("-" * 70)
    
    predictions = trainer.predict(X_test)
    evaluator = ModelEvaluator(y_test.values, predictions)
    
    # Calcula m√©tricas
    metrics = evaluator.calculate_metrics()
    
    # Gera relat√≥rio completo
    gerar_relatorio_completo(evaluator)
    
    # Compara√ß√£o detalhada
    print("\nüìã Compara√ß√£o Detalhada (primeiras 10 predi√ß√µes):")
    comparison = evaluator.compare_predictions(n_samples=10)
    print(comparison.to_string())
    
    # ========================================
    # 5. PERSIST√äNCIA DO MODELO
    # ========================================
    print("\n[ETAPA 5] PERSIST√äNCIA DO MODELO")
    print("-" * 70)
    
    salvar_modelo_producao(trainer)
    
    # Demonstra carregamento
    demonstrar_carregamento_modelo(X_test.iloc[:1])
    
    # ========================================
    # 6. PREDI√á√ÉO EM BATCH
    # ========================================
    print("\n[ETAPA 6] PREDI√á√ÉO EM BATCH")
    print("-" * 70)
    
    # Simula m√∫ltiplos carros para avaliar
    carros_novos = pd.DataFrame({
        'year': [2023, 2020, 2018, 2022, 2019],
        'mileage': [5000, 30000, 60000, 10000, 45000],
        'engine_size': [2.0, 1.6, 3.0, 2.5, 1.8],
        'horsepower': [180, 120, 250, 200, 140],
        'num_doors': [4, 4, 2, 4, 4]
    })
    
    precos_preditos = trainer.predict(carros_novos)
    
    print("\nüìä Predi√ß√µes em Batch:")
    resultado_batch = carros_novos.copy()
    resultado_batch['Pre√ßo_Predito'] = precos_preditos
    print(resultado_batch.to_string())
    
    print("\nüí∞ Estat√≠sticas dos Pre√ßos Preditos:")
    print(f"   ‚Ä¢ M√©dia: ${precos_preditos.mean():,.2f}")
    print(f"   ‚Ä¢ M√≠nimo: ${precos_preditos.min():,.2f}")
    print(f"   ‚Ä¢ M√°ximo: ${precos_preditos.max():,.2f}")
    
    # ========================================
    # CONCLUS√ÉO
    # ========================================
    print("\n" + "=" * 70)
    print("‚úÖ EXEMPLO AVAN√áADO CONCLU√çDO!")
    print("=" * 70)
    print("\nüìö Recursos Demonstrados:")
    print("   ‚úì Valida√ß√£o completa de dados")
    print("   ‚úì An√°lise de import√¢ncia de features")
    print("   ‚úì M√©tricas e intervalos de confian√ßa")
    print("   ‚úì Salvamento/carregamento de modelos")
    print("   ‚úì Predi√ß√µes em batch")
    print("=" * 70)


if __name__ == "__main__":
    main()
